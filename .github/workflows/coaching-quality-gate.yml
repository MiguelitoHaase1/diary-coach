name: Coaching Quality Gate

on:
  pull_request:
    types: [opened, synchronize, labeled]

jobs:
  eval-regression:
    # Only run if PR has 'eval-impact' label
    if: contains(github.event.pull_request.labels.*.name, 'eval-impact')
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install langsmith
        
    - name: Run coaching quality evaluation
      env:
        LANGSMITH_API_KEY: ${{ secrets.LANGSMITH_API_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        LANGSMITH_PROJECT: diary-coach-evals
      run: |
        python scripts/ci_eval_check.py
        
    - name: Comment PR with results
      if: always()  # Run even if evaluation fails
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // Check if results file exists
          if (!fs.existsSync('eval_results.json')) {
            const errorComment = `## ðŸ”´ Coaching Quality Check Failed
            
            The evaluation script failed to generate results. Please check the workflow logs for details.
            
            This may indicate:
            - Missing or invalid API keys
            - Dataset not found in LangSmith
            - Coach implementation errors
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: errorComment
            });
            return;
          }
          
          // Load and process results
          const results = JSON.parse(fs.readFileSync('eval_results.json'));
          
          let comment = '## ðŸŽ¯ Coaching Quality Check\n\n';
          
          // Overall status
          if (results.any_regression) {
            comment += 'ðŸ”´ **REGRESSION DETECTED** - This PR may impact coaching quality\n\n';
          } else {
            comment += 'âœ… **QUALITY MAINTAINED** - No significant regressions detected\n\n';
          }
          
          // Detailed metrics
          comment += '### Evaluation Results\n\n';
          comment += '| Metric | Baseline | Current | Change | Status |\n';
          comment += '|--------|----------|---------|--------|--------|\n';
          
          for (const [metric, data] of Object.entries(results)) {
            // Skip metadata fields
            if (['langsmith_url', 'any_regression', 'timestamp', 'threshold'].includes(metric)) {
              continue;
            }
            
            const emoji = data.regression ? 'ðŸ”´' : (data.change > 0 ? 'ðŸŸ¢' : 'ðŸŸ¡');
            const change = data.change >= 0 ? `+${data.change.toFixed(3)}` : data.change.toFixed(3);
            const changePercent = data.change_percent >= 0 ? `+${data.change_percent.toFixed(1)}%` : `${data.change_percent.toFixed(1)}%`;
            const status = data.regression ? 'REGRESSION' : (data.change > 0 ? 'IMPROVED' : 'STABLE');
            
            // Format metric name
            const displayName = metric.replace('Evaluator', '').replace(/_/g, ' ');
            
            comment += `| ${displayName} | ${data.baseline.toFixed(3)} | ${data.current.toFixed(3)} | ${change} (${changePercent}) | ${emoji} ${status} |\n`;
          }
          
          // Additional info
          comment += `\n### Details\n`;
          comment += `- **Regression Threshold**: ${(results.threshold * 100).toFixed(0)}% drop\n`;
          comment += `- **Evaluation Time**: ${new Date(results.timestamp).toLocaleString()}\n`;
          comment += `- **LangSmith Dashboard**: [View Full Report](${results.langsmith_url})\n`;
          
          // Guidance
          if (results.any_regression) {
            comment += `\n### ðŸš¨ Action Required\n`;
            comment += `One or more coaching metrics have regressed significantly. Please:\n`;
            comment += `1. Review the changes in this PR that might affect coaching behavior\n`;
            comment += `2. Test coaching conversations manually to verify quality\n`;
            comment += `3. Consider if the regression is acceptable for the intended changes\n`;
            comment += `4. Update baseline scores if the change is intentional\n`;
          } else {
            comment += `\n### âœ… Ready to Merge\n`;
            comment += `All coaching quality metrics are maintained or improved. No action required.\n`;
          }
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
          
    - name: Upload evaluation artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-results
        path: eval_results.json
        retention-days: 30